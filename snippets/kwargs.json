// Ultralytics YOLO ðŸš€, AGPL-3.0 license

{
    "Ultralytics YOLO Predict Keyword Arguments":{
		"prefix": "ultra.kwargs-predict",
		"body":[
			"${1:model}.predict(",
			"    source=${4:\"\"},            # (str, optional) source directory for images or videos",
			"    imgsz=${5:640},            # (int | list) input images size as int or list[w,h] for predict",
			"    conf=${6:0.25},            # (float) minimum confidence threshold",
			"    iou=${7:0.7},              # (float) intersection over union (IoU) threshold for NMS",
			"    vid_stride=${8:1},         # (int) video frame-rate stride",
			"    stream_buffer=${9|False,True|},  # (bool) buffer all streaming frames (True) or return the most recent frame (False)",
			"    visualize=${10|False,True|},      # (bool) visualize model features",
			"    augment=${11|False,True|},        # (bool) apply image augmentation to prediction sources",
			"    agnostic_nms=${12|False,True|},   # (bool) class-agnostic NMS",
			"    classes=${13:None},         # (int | list[int], optional) filter results by class, i.e. classes=0, or classes=[0,2,3]",
			"    retina_masks=${14|False,True|},   # (bool) use high-resolution segmentation masks",
			"    embed=${15:None},           # (list[int], optional) return feature vectors/embeddings from given layers",
			"    show=${16|False,True|},           # (bool) show predicted images and videos if environment allows",
			"    save=${17|True,False|},            # (bool) save prediction results",
			"    save_frames=${18|False,True|},    # (bool) save predicted individual video frames",
			"    save_txt=${19|False,True|},       # (bool) save results as .txt file",
			"    save_conf=${20|False,True|},      # (bool) save results with confidence scores",
			"    save_crop=${21|False,True|},      # (bool) save cropped images with results",
			"    stream=${22|False,True|},         # (bool) for processing long videos or numerous images with reduced memory usage by returning a generator",
			"    verbose=${23|True,False|},         # (bool) enable/disable verbose inference logging in the terminal",
			")$0"
		],
		"description": "Snippet using model predict method, including all keyword arguments and defaults."
	},

    "Ultralytics Track Keyword Arguments":{
		"prefix":"ultra.kwargs-track",
		"body":[
			"${1:model}.track(",
			"    source=${4:\"\"},            # (str, optional) source directory for images or videos",
			"    imgsz=${5:640},            # (int | list) input images size as int or list[w,h] for predict",
			"    conf=${6:0.25},            # (float) minimum confidence threshold",
			"    iou=${7:0.7},              # (float) intersection over union (IoU) threshold for NMS",
			"    persist=${8|False,True|},        # (bool) persist track-ids across frames",
			"    tracker=\"${9|botsort,bytetrack|}\",    # (str) tracker type, choices=[botsort.yaml, bytetrack.yaml]",
			"    vid_stride=${10:1},         # (int) video frame-rate stride",
			"    stream_buffer=${11|False,True|},  # (bool) buffer all streaming frames (True) or return the most recent frame (False)",
			"    visualize=${12|False,True|},      # (bool) visualize model features",
			"    augment=${13|False,True|},        # (bool) apply image augmentation to prediction sources",
			"    agnostic_nms=${14|False,True|},   # (bool) class-agnostic NMS",
			"    classes=${15:None},         # (int | list[int], optional) filter results by class, i.e. classes=0, or classes=[0,2,3]",
			"    retina_masks=${16|False,True|},   # (bool) use high-resolution segmentation masks",
			"    embed=${17:None},           # (list[int], optional) return feature vectors/embeddings from given layers",
			"    show=${18|False,True|},           # (bool) show predicted images and videos if environment allows",
			"    save=${19|True,False|},            # (bool) save prediction results",
			"    save_frames=${20|False,True|},    # (bool) save predicted individual video frames",
			"    save_txt=${21|False,True|},       # (bool) save results as .txt file",
			"    save_conf=${20|False,True|},      # (bool) save results with confidence scores",
			"    save_crop=${21|False,True|},      # (bool) save cropped images with results",
			"    stream=${22|False,True|},         # (bool) for processing long videos or numerous images with reduced memory usage by returning a generator",
			"    verbose=${23|True,False|},         # (bool) enable/disable verbose inference logging in the terminal",
			")$0"
		],
		"description": "Snippet using model track method, including all keyword arguments and defaults."
	},

    "Ultralytics YOLO Train Keyword Arguments":{
		"prefix": "ultra.kwargs-train",
		"body":[
			"${1:model}.train(",
		    	"    data=\"${4:coco8.yaml}\",           # (str, optional) path to data file, i.e. coco8.yaml",
		    	"    epochs=${5:100},                  # (int) number of epochs to train for",
		    	"    time=${6:None},                   # (float, optional) number of hours to train for, overrides epochs if supplied",
		    	"    patience=${7:100},                # (int) epochs to wait for no observable improvement for early stopping of training",
		    	"    batch=${8:16},                    # (int) number of images per batch (-1 for AutoBatch)",
		    	"    imgsz=${9:640},                   # (int | list) input images size as int for train and val modes, or list[w,h] for predict and export modes",
		    	"    save=${10|True,False|},                   # (bool) save train checkpoints and predict results",
		    	"    save_period=${11:-1},              # (int) Save checkpoint every x epochs (disabled if < 1)",
		    	"    cache=${12|False,True,'ram','disk'|},                 # (bool) True/ram, disk or False. Use cache for data loading",
		    	"    device=${13|None,'cpu','cuda',0|},                 # (int | str | list, optional) device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu",
		    	"    workers=${14:8},                   # (int) number of worker threads for data loading (per RANK if DDP)",
		    	"    project=${15:None},                # (str, optional) project name",
		    	"    name=${16:None},                   # (str, optional) experiment name, results saved to 'project/name' directory",
		    	"    exist_ok=${17|False,True|},              # (bool) whether to overwrite existing experiment",
		    	"    val=${18|True,False|},                    # (bool) validate/test during training",
		    	"    pretrained=${19|True,False|},             # (bool | str) whether to use a pretrained model (bool) or a model to load weights from (str)",
		    	"    optimizer=\"${20|SGD,Adam,Adamax,AdamW,NAdam,RAdam,RMSProp,auto|}\",             # (str) optimizer to use, choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]",
		    	"    verbose=${21|True,False|},                # (bool) whether to print verbose output",
		    	"    seed=${22:0},                      # (int) random seed for reproducibility",
		    	"    deterministic=${23|True,False|},          # (bool) whether to enable deterministic mode",
		    	"    single_cls=${24|False,True|},            # (bool) train multi-class data as single-class",
		    	"    rect=${25|False,True|},                  # (bool) rectangular training if mode='train' or rectangular validation if mode='val'",
		    	"    cos_lr=${26|False,True|},                # (bool) use cosine learning rate scheduler",
		    	"    close_mosaic=${27:10},             # (int) disable mosaic augmentation for final epochs (0 to disable)",
		    	"    resume=${28|False,True|},                # (bool) resume training from last checkpoint",
		    	"    amp=${29|True,False|},                    # (bool) Automatic Mixed Precision (AMP) training, choices=[True, False], True runs AMP check",
		    	"    fraction=${30:1.0},                # (float) dataset fraction to train on (default is 1.0, all images in train set)",
		    	"    profile=${31|False,True|},               # (bool) profile ONNX and TensorRT speeds during training for loggers",
		    	"    freeze=${32:None},                 # (int | list, optional) freeze first n layers, or freeze list of layer indices during training",
		    	"    multi_scale=${33|False,True|},           # (bool) Whether to use multiscale during training",
		    	"    plots=${34|True,False|},                  # (bool) save plots and images during train/val",
		    	"    # Segmentation",
		    	"    overlap_mask=${35|True,False|},           # (bool) masks should overlap during training (segment train only)",
		    	"    mask_ratio=${36:4},                # (int) mask downsample ratio (segment train only)",
		    	"    # Classification",
		    	"    dropout=${37:0.0},                 # (float) use dropout regularization (classify train only)",
		    	"    # Hyperparameters",
		    	"    lr0=${38:0.01},                    # (float) initial learning rate (i.e. SGD=1E-2, Adam=1E-3)",
		    	"    lrf=${39:0.01},                    # (float) final learning rate (lr0 * lrf)",
		    	"    momentum=${40:0.937},              # (float) SGD momentum/Adam beta1",
		    	"    weight_decay=${41:0.0005},         # (float) optimizer weight decay 5e-4",
		    	"    warmup_epochs=${42:3.0},           # (float) warmup epochs (fractions ok)",
		    	"    warmup_momentum=${43:0.8},         # (float) warmup initial momentum",
		    	"    warmup_bias_lr=${44:0.1},          # (float) warmup initial bias lr",
		    	"    box=${45:7.5},                     # (float) box loss gain",
		    	"    cls=${46:0.5},                     # (float) cls loss gain (scale with pixels)",
		    	"    dfl=${47:1.5},                     # (float) dfl loss gain",
		    	"    pose=${48:12.0},                   # (float) pose loss gain",
		    	"    kobj=${49:1.0},                    # (float) keypoint obj loss gain",
		    	"    label_smoothing=${50:0.0},         # (float) label smoothing (fraction)",
		    	"    nbs=${51:64},                      # (int) nominal batch size",
		    	"    hsv_h=${52:0.015},                 # (float) image HSV-Hue augmentation (fraction)",
		    	"    hsv_s=${53:0.7},                   # (float) image HSV-Saturation augmentation (fraction)",
		    	"    hsv_v=${54:0.4},                   # (float) image HSV-Value augmentation (fraction)",
		    	"    degrees=${55:0.0},                 # (float) image rotation (+/- deg)",
		    	"    translate=${56:0.1},               # (float) image translation (+/- fraction)",
		    	"    scale=${57:0.5},                   # (float) image scale (+/- gain)",
		    	"    shear=${58:0.0},                   # (float) image shear (+/- deg)",
		    	"    perspective=${59:0.0},             # (float) image perspective (+/- fraction), range 0-0.001",
		    	"    flipud=${60:0.0},                  # (float) image flip up-down (probability)",
		    	"    fliplr=${61:0.5},                  # (float) image flip left-right (probability)",
		    	"    bgr=${62:0.0},                     # (float) image channel BGR (probability)",
		    	"    mosaic=${63:1.0},                  # (float) image mosaic (probability)",
		    	"    mixup=${64:0.0},                   # (float) image mixup (probability)",
		    	"    copy_paste=${65:0.0},              # (float) segment copy-paste (probability)",
		    	"    auto_augment=\"${66|randaugment,autoaugment,augmix|}\",  # (str) auto augmentation policy for classification (randaugment, autoaugment, augmix)",
		    	"    erasing=${67:0.4},                 # (float) probability of random erasing during classify training [0-0.9], 0 is no erasing, must be < 1.0.",
		    	"    crop_fraction=${68:1.0},           # (float) image crop fraction for classification [0.1-1], 1.0 is no crop, must be > 0.",
		    	")$0"
		],
		"description": "Snippet using model train method, including all keyword arguments and defaults."
	},

	"Ultralytics YOLO Validation Keyword Arguments":{
		"prefix": "ultra.kwargs-val",
		"body":[
			"${1:model}.val(",
			"    data=\"${2:coco8.yaml}\",  # (str) Specifies the path to the dataset configuration file (e.g., coco8.yaml).",
			"    imgsz=${3:640},          # (int) Defines the size of input images. All images are resized to this dimension before processing.",
			"    batch=${4:16},           # (int) Sets the number of images per batch. Use -1 for AutoBatch, which automatically adjusts based on GPU memory availability.",
			"    save_json=${5|False,True|},    # (bool) If True, saves the results to a JSON file for further analysis or integration with other tools.",
			"    save_hybrid=${6|False,True|},  # (bool) If True, saves a hybrid version of labels that combines original annotations with additional model predictions.",
			"    conf=${7:0.001},         # (float) Sets the minimum confidence threshold for detections. Detections with confidence below this threshold are discarded.",
			"    iou=${8:0.6},            # (float) Sets the Intersection Over Union (IoU) threshold for Non-Maximum Suppression (NMS). Helps in reducing duplicate detections.",
			"    max_det=${9:300},        # (int) Limits the maximum number of detections per image. Useful in dense scenes to prevent excessive detections.",
			"    half=${10|True,False|},          # (bool) Enables half-precision (FP16) computation, reducing memory usage and potentially increasing speed with minimal impact on accuracy.",
			"    device=${11:None},        # (str) Specifies the device for validation (cpu, cuda:0, etc.). Allows flexibility in utilizing CPU or GPU resources.",
			"    dnn=${12|False,True|},          # (bool) If True, uses the OpenCV DNN module for ONNX model inference, offering an alternative to PyTorch inference methods.",
			"    plots=${13|False,True|},        # (bool) When set to True, generates and saves plots of predictions versus ground truth for visual evaluation of the model's performance.",
			"    rect=${14|False,True|},         # (bool) If True, uses rectangular inference for batching, reducing padding and potentially increasing speed and efficiency.",
			"    split=\"${15|val,test,train|}\",        # (str) Determines the dataset split to use for validation (val, test, or train).",
			")$0"
		],
		"description": "Snippet using model val method, including all keyword arguments and defaults."
	}
}
