{
    "benchmark": [],
    "export": [
        {
            "Name": "export-args",
            "Mode": "export",
            "Args": [
                {
                    "Argument": "format",
                    "Default": "'torchscript'",
                    "Description": "Target format for the exported model, such as `'onnx'`, `'torchscript'`, `'tensorflow'`, or others, defining compatibility with various deployment environments.",
                    "Type": "str",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "imgsz",
                    "Default": "640",
                    "Description": "Desired image size for the model input. Can be an integer for square images or a tuple `(height, width)` for specific dimensions.",
                    "Type": "int` or `tuple",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "keras",
                    "Default": "False",
                    "Description": "Enables export to Keras format for [TensorFlow](https://www.ultralytics.com/glossary/tensorflow) SavedModel, providing compatibility with TensorFlow serving and APIs.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "optimize",
                    "Default": "False",
                    "Description": "Applies optimization for mobile devices when exporting to TorchScript, potentially reducing model size and improving performance.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "half",
                    "Default": "False",
                    "Description": "Enables FP16 (half-precision) quantization, reducing model size and potentially speeding up inference on supported hardware.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "int8",
                    "Default": "False",
                    "Description": "Activates INT8 quantization, further compressing the model and speeding up inference with minimal [accuracy](https://www.ultralytics.com/glossary/accuracy) loss, primarily for edge devices.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "dynamic",
                    "Default": "False",
                    "Description": "Allows dynamic input sizes for ONNX, TensorRT and OpenVINO exports, enhancing flexibility in handling varying image dimensions.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "simplify",
                    "Default": "True",
                    "Description": "Simplifies the model graph for ONNX exports with `onnxslim`, potentially improving performance and compatibility.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "opset",
                    "Default": "None",
                    "Description": "Specifies the ONNX opset version for compatibility with different ONNX parsers and runtimes. If not set, uses the latest supported version.",
                    "Type": "int",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "workspace",
                    "Default": "None",
                    "Description": "Sets the maximum workspace size in GiB for TensorRT optimizations, balancing memory usage and performance; use `None` for auto-allocation by TensorRT up to device maximum.",
                    "Type": "float` or `None",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "nms",
                    "Default": "False",
                    "Description": "Adds Non-Maximum Suppression (NMS) to the exported model when supported (see Export Formats), improving detection post-processing efficiency.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "batch",
                    "Default": "1",
                    "Description": "Specifies export model batch inference size or the max number of images the exported model will process concurrently in `predict` mode.",
                    "Type": "int",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "device",
                    "Default": "None",
                    "Description": "Specifies the device for exporting: GPU (`device=0`), CPU (`device=cpu`), MPS for Apple silicon (`device=mps`) or DLA for NVIDIA Jetson (`device=dla:0` or `device=dla:1`).",
                    "Type": "str",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "data",
                    "Default": "coco8.yaml",
                    "Description": "Path to the [dataset](https://docs.ultralytics.com/datasets) configuration file (default: `coco8.yaml`), essential for quantization.",
                    "Type": "str",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                }
            ]
        }
    ],
    "index": [],
    "predict": [
        {
            "Name": "None",
            "Mode": "predict",
            "Args": [
                {
                    "Argument": "source",
                    "Default": "'ultralytics/assets'",
                    "Description": "Specifies the data source for inference. Can be an image path, video file, directory, URL, or device ID for live feeds. Supports a wide range of formats and sources, enabling flexible application across [different types of input](/modes/predict.md/#inference-sources).",
                    "Type": "str",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "conf",
                    "Default": "0.25",
                    "Description": "Sets the minimum confidence threshold for detections. Objects detected with confidence below this threshold will be disregarded. Adjusting this value can help reduce false positives.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "iou",
                    "Default": "0.7",
                    "Description": "[Intersection Over Union](https://www.ultralytics.com/glossary/intersection-over-union-iou) (IoU) threshold for Non-Maximum Suppression (NMS). Lower values result in fewer detections by eliminating overlapping boxes, useful for reducing duplicates.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "imgsz",
                    "Default": "640",
                    "Description": "Defines the image size for inference. Can be a single integer `640` for square resizing or a (height, width) tuple. Proper sizing can improve detection [accuracy](https://www.ultralytics.com/glossary/accuracy) and processing speed.",
                    "Type": "int` or `tuple",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "half",
                    "Default": "False",
                    "Description": "Enables half-[precision](https://www.ultralytics.com/glossary/precision) (FP16) inference, which can speed up model inference on supported GPUs with minimal impact on accuracy.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "device",
                    "Default": "None",
                    "Description": "Specifies the device for inference (e.g., `cpu`, `cuda:0` or `0`). Allows users to select between CPU, a specific GPU, or other compute devices for model execution.",
                    "Type": "str",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "batch",
                    "Default": "1",
                    "Description": "Specifies the batch size for inference (only works when the source is [a directory, video file or `.txt` file](/modes/predict.md/#inference-sources)). A larger batch size can provide higher throughput, shortening the total amount of time required for inference.",
                    "Type": "int",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "max_det",
                    "Default": "300",
                    "Description": "Maximum number of detections allowed per image. Limits the total number of objects the model can detect in a single inference, preventing excessive outputs in dense scenes.",
                    "Type": "int",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "vid_stride",
                    "Default": "1",
                    "Description": "Frame stride for video inputs. Allows skipping frames in videos to speed up processing at the cost of temporal resolution. A value of 1 processes every frame, higher values skip frames.",
                    "Type": "int",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "stream_buffer",
                    "Default": "False",
                    "Description": "Determines whether to queue incoming frames for video streams. If `False`, old frames get dropped to accommodate new frames (optimized for real-time applications). If `True', queues new frames in a buffer, ensuring no frames get skipped, but will cause latency if inference FPS is lower than stream FPS.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "visualize",
                    "Default": "False",
                    "Description": "Activates visualization of model features during inference, providing insights into what the model is \"seeing\". Useful for debugging and model interpretation.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "augment",
                    "Default": "False",
                    "Description": "Enables test-time augmentation (TTA) for predictions, potentially improving detection robustness at the cost of inference speed.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "agnostic_nms",
                    "Default": "False",
                    "Description": "Enables class-agnostic Non-Maximum Suppression (NMS), which merges overlapping boxes of different classes. Useful in multi-class detection scenarios where class overlap is common.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "classes",
                    "Default": "None",
                    "Description": "Filters predictions to a set of class IDs. Only detections belonging to the specified classes will be returned. Useful for focusing on relevant objects in multi-class detection tasks.",
                    "Type": "list[int]",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "retina_masks",
                    "Default": "False",
                    "Description": "Returns high-resolution segmentation masks. The returned masks (`masks.data`) will match the original image size if enabled. If disabled, they have the image size used during inference.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "embed",
                    "Default": "None",
                    "Description": "Specifies the layers from which to extract feature vectors or [embeddings](https://www.ultralytics.com/glossary/embeddings). Useful for downstream tasks like clustering or similarity search.",
                    "Type": "list[int]",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "project",
                    "Default": "None",
                    "Description": "Name of the project directory where prediction outputs are saved if `save` is enabled.",
                    "Type": "str",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "name",
                    "Default": "None",
                    "Description": "Name of the prediction run. Used for creating a subdirectory within the project folder, where prediction outputs are stored if `save` is enabled.",
                    "Type": "str",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                }
            ]
        },
        {
            "Name": "visualization-args",
            "Mode": "predict",
            "Args": [
                {
                    "Argument": "show",
                    "Default": "False",
                    "Description": "If `True`, displays the annotated images or videos in a window. Useful for immediate visual feedback during development or testing.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "save",
                    "Default": "False` or `True",
                    "Description": "Enables saving of the annotated images or videos to file. Useful for documentation, further analysis, or sharing results. Defaults to True when using CLI & False when used in Python.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "save_frames",
                    "Default": "False",
                    "Description": "When processing videos, saves individual frames as images. Useful for extracting specific frames or for detailed frame-by-frame analysis.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "save_txt",
                    "Default": "False",
                    "Description": "Saves detection results in a text file, following the format `[class] [x_center] [y_center] [width] [height] [confidence]`. Useful for integration with other analysis tools.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "save_conf",
                    "Default": "False",
                    "Description": "Includes confidence scores in the saved text files. Enhances the detail available for post-processing and analysis.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "save_crop",
                    "Default": "False",
                    "Description": "Saves cropped images of detections. Useful for dataset augmentation, analysis, or creating focused datasets for specific objects.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "show_labels",
                    "Default": "True",
                    "Description": "Displays labels for each detection in the visual output. Provides immediate understanding of detected objects.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "show_conf",
                    "Default": "True",
                    "Description": "Displays the confidence score for each detection alongside the label. Gives insight into the model's certainty for each detection.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "show_boxes",
                    "Default": "True",
                    "Description": "Draws bounding boxes around detected objects. Essential for visual identification and location of objects in images or video frames.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "line_width",
                    "Default": "None",
                    "Description": "Specifies the line width of bounding boxes. If `None`, the line width is automatically adjusted based on the image size. Provides visual customization for clarity.",
                    "Type": "None` or `int",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                }
            ]
        }
    ],
    "track": [],
    "train": [
        {
            "Name": "None",
            "Mode": "train",
            "Args": [
                {
                    "Argument": "model",
                    "Default": "None",
                    "Description": "Specifies the model file for training. Accepts a path to either a `.pt` pretrained model or a `.yaml` configuration file. Essential for defining the model structure or initializing weights.",
                    "Type": "str",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "data",
                    "Default": "None",
                    "Description": "Path to the dataset configuration file (e.g., `coco8.yaml`). This file contains dataset-specific parameters, including paths to training and [validation data](https://www.ultralytics.com/glossary/validation-data), class names, and number of classes.",
                    "Type": "str",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "epochs",
                    "Default": "100",
                    "Description": "Total number of training epochs. Each [epoch](https://www.ultralytics.com/glossary/epoch) represents a full pass over the entire dataset. Adjusting this value can affect training duration and model performance.",
                    "Type": "int",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "time",
                    "Default": "None",
                    "Description": "Maximum training time in hours. If set, this overrides the `epochs` argument, allowing training to automatically stop after the specified duration. Useful for time-constrained training scenarios.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "patience",
                    "Default": "100",
                    "Description": "Number of epochs to wait without improvement in validation metrics before early stopping the training. Helps prevent [overfitting](https://www.ultralytics.com/glossary/overfitting) by stopping training when performance plateaus.",
                    "Type": "int",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "batch",
                    "Default": "16",
                    "Description": "[Batch size](https://www.ultralytics.com/glossary/batch-size), with three modes: set as an integer (e.g., `batch=16`), auto mode for 60% GPU memory utilization (`batch=-1`), or auto mode with specified utilization fraction (`batch=0.70`).",
                    "Type": "int",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "imgsz",
                    "Default": "640",
                    "Description": "Target image size for training. All images are resized to this dimension before being fed into the model. Affects model [accuracy](https://www.ultralytics.com/glossary/accuracy) and computational complexity.",
                    "Type": "int` or `list",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "save",
                    "Default": "True",
                    "Description": "Enables saving of training checkpoints and final model weights. Useful for resuming training or [model deployment](https://www.ultralytics.com/glossary/model-deployment).",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "save_period",
                    "Default": "-1",
                    "Description": "Frequency of saving model checkpoints, specified in epochs. A value of -1 disables this feature. Useful for saving interim models during long training sessions.",
                    "Type": "int",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "cache",
                    "Default": "False",
                    "Description": "Enables caching of dataset images in memory (`True`/`ram`), on disk (`disk`), or disables it (`False`). Improves training speed by reducing disk I/O at the cost of increased memory usage.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "device",
                    "Default": "None",
                    "Description": "Specifies the computational device(s) for training: a single GPU (`device=0`), multiple GPUs (`device=0,1`), CPU (`device=cpu`), or MPS for Apple silicon (`device=mps`).",
                    "Type": "int` or `str` or `list",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "workers",
                    "Default": "8",
                    "Description": "Number of worker threads for data loading (per `RANK` if Multi-GPU training). Influences the speed of data preprocessing and feeding into the model, especially useful in multi-GPU setups.",
                    "Type": "int",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "project",
                    "Default": "None",
                    "Description": "Name of the project directory where training outputs are saved. Allows for organized storage of different experiments.",
                    "Type": "str",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "name",
                    "Default": "None",
                    "Description": "Name of the training run. Used for creating a subdirectory within the project folder, where training logs and outputs are stored.",
                    "Type": "str",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "exist_ok",
                    "Default": "False",
                    "Description": "If True, allows overwriting of an existing project/name directory. Useful for iterative experimentation without needing to manually clear previous outputs.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "pretrained",
                    "Default": "True",
                    "Description": "Determines whether to start training from a pretrained model. Can be a boolean value or a string path to a specific model from which to load weights. Enhances training efficiency and model performance.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "optimizer",
                    "Default": "'auto'",
                    "Description": "Choice of optimizer for training. Options include `SGD`, `Adam`, `AdamW`, `NAdam`, `RAdam`, `RMSProp` etc., or `auto` for automatic selection based on model configuration. Affects convergence speed and stability.",
                    "Type": "str",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "seed",
                    "Default": "0",
                    "Description": "Sets the random seed for training, ensuring reproducibility of results across runs with the same configurations.",
                    "Type": "int",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "deterministic",
                    "Default": "True",
                    "Description": "Forces deterministic algorithm use, ensuring reproducibility but may affect performance and speed due to the restriction on non-deterministic algorithms.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "single_cls",
                    "Default": "False",
                    "Description": "Treats all classes in multi-class datasets as a single class during training. Useful for binary classification tasks or when focusing on object presence rather than classification.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "classes",
                    "Default": "None",
                    "Description": "Specifies a list of class IDs to train on. Useful for filtering out and focusing only on certain classes during training.",
                    "Type": "list[int]",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "rect",
                    "Default": "False",
                    "Description": "Enables rectangular training, optimizing batch composition for minimal padding. Can improve efficiency and speed but may affect model accuracy.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "multi_scale",
                    "Default": "False",
                    "Description": "Enables multi-scale training by increasing/decreasing `imgsz` by upto a factor of `0.5` during training. Trains the model to be more accurate with multiple `imgsz` during inference.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "cos_lr",
                    "Default": "False",
                    "Description": "Utilizes a cosine [learning rate](https://www.ultralytics.com/glossary/learning-rate) scheduler, adjusting the learning rate following a cosine curve over epochs. Helps in managing learning rate for better convergence.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "close_mosaic",
                    "Default": "10",
                    "Description": "Disables mosaic [data augmentation](https://www.ultralytics.com/glossary/data-augmentation) in the last N epochs to stabilize training before completion. Setting to 0 disables this feature.",
                    "Type": "int",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "resume",
                    "Default": "False",
                    "Description": "Resumes training from the last saved checkpoint. Automatically loads model weights, optimizer state, and epoch count, continuing training seamlessly.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "amp",
                    "Default": "True",
                    "Description": "Enables Automatic [Mixed Precision](https://www.ultralytics.com/glossary/mixed-precision) (AMP) training, reducing memory usage and possibly speeding up training with minimal impact on accuracy.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "fraction",
                    "Default": "1.0",
                    "Description": "Specifies the fraction of the dataset to use for training. Allows for training on a subset of the full dataset, useful for experiments or when resources are limited.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "profile",
                    "Default": "False",
                    "Description": "Enables profiling of ONNX and TensorRT speeds during training, useful for optimizing model deployment.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "freeze",
                    "Default": "None",
                    "Description": "Freezes the first N layers of the model or specified layers by index, reducing the number of trainable parameters. Useful for fine-tuning or [transfer learning](https://www.ultralytics.com/glossary/transfer-learning).",
                    "Type": "int` or `list",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "lr0",
                    "Default": "0.01",
                    "Description": "Initial learning rate (i.e. `SGD=1E-2`, `Adam=1E-3`) . Adjusting this value is crucial for the optimization process, influencing how rapidly model weights are updated.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "lrf",
                    "Default": "0.01",
                    "Description": "Final learning rate as a fraction of the initial rate = (`lr0 * lrf`), used in conjunction with schedulers to adjust the learning rate over time.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "momentum",
                    "Default": "0.937",
                    "Description": "Momentum factor for SGD or beta1 for [Adam optimizers](https://www.ultralytics.com/glossary/adam-optimizer), influencing the incorporation of past gradients in the current update.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "weight_decay",
                    "Default": "0.0005",
                    "Description": "L2 [regularization](https://www.ultralytics.com/glossary/regularization) term, penalizing large weights to prevent overfitting.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "warmup_epochs",
                    "Default": "3.0",
                    "Description": "Number of epochs for learning rate warmup, gradually increasing the learning rate from a low value to the initial learning rate to stabilize training early on.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "warmup_momentum",
                    "Default": "0.8",
                    "Description": "Initial momentum for warmup phase, gradually adjusting to the set momentum over the warmup period.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "warmup_bias_lr",
                    "Default": "0.1",
                    "Description": "Learning rate for bias parameters during the warmup phase, helping stabilize model training in the initial epochs.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "box",
                    "Default": "7.5",
                    "Description": "Weight of the box loss component in the [loss function](https://www.ultralytics.com/glossary/loss-function), influencing how much emphasis is placed on accurately predicting [bounding box](https://www.ultralytics.com/glossary/bounding-box) coordinates.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "cls",
                    "Default": "0.5",
                    "Description": "Weight of the classification loss in the total loss function, affecting the importance of correct class prediction relative to other components.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "dfl",
                    "Default": "1.5",
                    "Description": "Weight of the distribution focal loss, used in certain YOLO versions for fine-grained classification.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "pose",
                    "Default": "12.0",
                    "Description": "Weight of the pose loss in models trained for pose estimation, influencing the emphasis on accurately predicting pose keypoints.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "kobj",
                    "Default": "2.0",
                    "Description": "Weight of the keypoint objectness loss in pose estimation models, balancing detection confidence with pose accuracy.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "nbs",
                    "Default": "64",
                    "Description": "Nominal batch size for normalization of loss.",
                    "Type": "int",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "overlap_mask",
                    "Default": "True",
                    "Description": "Determines whether object masks should be merged into a single mask for training, or kept separate for each object. In case of overlap, the smaller mask is overlaid on top of the larger mask during merge.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "mask_ratio",
                    "Default": "4",
                    "Description": "Downsample ratio for segmentation masks, affecting the resolution of masks used during training.",
                    "Type": "int",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "dropout",
                    "Default": "0.0",
                    "Description": "Dropout rate for regularization in classification tasks, preventing overfitting by randomly omitting units during training.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "val",
                    "Default": "True",
                    "Description": "Enables validation during training, allowing for periodic evaluation of model performance on a separate dataset.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "plots",
                    "Default": "False",
                    "Description": "Generates and saves plots of training and validation metrics, as well as prediction examples, providing visual insights into model performance and learning progression.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                }
            ]
        },
        {
            "Name": "augmentation-args",
            "Mode": "train",
            "Args": [
                {
                    "Argument": "hsv_h",
                    "Default": "0.015",
                    "Description": "Adjusts the hue of the image by a fraction of the color wheel, introducing color variability. Helps the model generalize across different lighting conditions.",
                    "Type": "float",
                    "Range": [
                        0.0,
                        1.0
                    ],
                    "Min": 0.0,
                    "Max": 1.0
                },
                {
                    "Argument": "hsv_s",
                    "Default": "0.7",
                    "Description": "Alters the saturation of the image by a fraction, affecting the intensity of colors. Useful for simulating different environmental conditions.",
                    "Type": "float",
                    "Range": [
                        0.0,
                        1.0
                    ],
                    "Min": 0.0,
                    "Max": 1.0
                },
                {
                    "Argument": "hsv_v",
                    "Default": "0.4",
                    "Description": "Modifies the value (brightness) of the image by a fraction, helping the model to perform well under various lighting conditions.",
                    "Type": "float",
                    "Range": [
                        0.0,
                        1.0
                    ],
                    "Min": 0.0,
                    "Max": 1.0
                },
                {
                    "Argument": "degrees",
                    "Default": "0.0",
                    "Description": "Rotates the image randomly within the specified degree range, improving the model's ability to recognize objects at various orientations.",
                    "Type": "float",
                    "Range": [
                        -180,
                        180
                    ],
                    "Min": -180,
                    "Max": 180
                },
                {
                    "Argument": "translate",
                    "Default": "0.1",
                    "Description": "Translates the image horizontally and vertically by a fraction of the image size, aiding in learning to detect partially visible objects.",
                    "Type": "float",
                    "Range": [
                        0.0,
                        1.0
                    ],
                    "Min": 0.0,
                    "Max": 1.0
                },
                {
                    "Argument": "scale",
                    "Default": "0.5",
                    "Description": "Scales the image by a gain factor, simulating objects at different distances from the camera.",
                    "Type": "float",
                    "Range": [
                        0.0
                    ],
                    "Min": 0.0,
                    "Max": 0.0
                },
                {
                    "Argument": "shear",
                    "Default": "0.0",
                    "Description": "Shears the image by a specified degree, mimicking the effect of objects being viewed from different angles.",
                    "Type": "float",
                    "Range": [
                        -180,
                        180
                    ],
                    "Min": -180,
                    "Max": 180
                },
                {
                    "Argument": "perspective",
                    "Default": "0.0",
                    "Description": "Applies a random perspective transformation to the image, enhancing the model's ability to understand objects in 3D space.",
                    "Type": "float",
                    "Range": [
                        0.0,
                        0.001
                    ],
                    "Min": 0.0,
                    "Max": 0.001
                },
                {
                    "Argument": "flipud",
                    "Default": "0.0",
                    "Description": "Flips the image upside down with the specified probability, increasing the data variability without affecting the object's characteristics.",
                    "Type": "float",
                    "Range": [
                        0.0,
                        1.0
                    ],
                    "Min": 0.0,
                    "Max": 1.0
                },
                {
                    "Argument": "fliplr",
                    "Default": "0.5",
                    "Description": "Flips the image left to right with the specified probability, useful for learning symmetrical objects and increasing dataset diversity.",
                    "Type": "float",
                    "Range": [
                        0.0,
                        1.0
                    ],
                    "Min": 0.0,
                    "Max": 1.0
                },
                {
                    "Argument": "bgr",
                    "Default": "0.0",
                    "Description": "Flips the image channels from RGB to BGR with the specified probability, useful for increasing robustness to incorrect channel ordering.",
                    "Type": "float",
                    "Range": [
                        0.0,
                        1.0
                    ],
                    "Min": 0.0,
                    "Max": 1.0
                },
                {
                    "Argument": "mosaic",
                    "Default": "1.0",
                    "Description": "Combines four training images into one, simulating different scene compositions and object interactions. Highly effective for complex scene understanding.",
                    "Type": "float",
                    "Range": [
                        0.0,
                        1.0
                    ],
                    "Min": 0.0,
                    "Max": 1.0
                },
                {
                    "Argument": "mixup",
                    "Default": "0.0",
                    "Description": "Blends two images and their labels, creating a composite image. Enhances the model's ability to generalize by introducing label noise and visual variability.",
                    "Type": "float",
                    "Range": [
                        0.0,
                        1.0
                    ],
                    "Min": 0.0,
                    "Max": 1.0
                },
                {
                    "Argument": "copy_paste",
                    "Default": "0.0",
                    "Description": "Copies and pastes objects across images, useful for increasing object instances and learning object occlusion. Requires segmentation labels.",
                    "Type": "float",
                    "Range": [
                        0.0,
                        1.0
                    ],
                    "Min": 0.0,
                    "Max": 1.0
                },
                {
                    "Argument": "copy_paste_mode",
                    "Default": "flip",
                    "Description": "Copy-Paste augmentation method selection among the options of (`\"flip\"`, `\"mixup\"`).",
                    "Type": "str",
                    "Range": "-",
                    "Min": "-",
                    "Max": "-"
                },
                {
                    "Argument": "auto_augment",
                    "Default": "randaugment",
                    "Description": "Automatically applies a predefined augmentation policy (`randaugment`, `autoaugment`, `augmix`), optimizing for classification tasks by diversifying the visual features.",
                    "Type": "str",
                    "Range": "-",
                    "Min": "-",
                    "Max": "-"
                },
                {
                    "Argument": "erasing",
                    "Default": "0.4",
                    "Description": "Randomly erases a portion of the image during classification training, encouraging the model to focus on less obvious features for recognition.",
                    "Type": "float",
                    "Range": [
                        0.0,
                        0.9
                    ],
                    "Min": 0.0,
                    "Max": 0.9
                },
                {
                    "Argument": "crop_fraction",
                    "Default": "1.0",
                    "Description": "Crops the classification image to a fraction of its size to emphasize central features and adapt to object scales, reducing background distractions.",
                    "Type": "float",
                    "Range": [
                        0.1,
                        1.0
                    ],
                    "Min": 0.1,
                    "Max": 1.0
                }
            ]
        }
    ],
    "val": [
        {
            "Name": "None",
            "Mode": "val",
            "Args": [
                {
                    "Argument": "data",
                    "Default": "None",
                    "Description": "Specifies the path to the dataset configuration file (e.g., `coco8.yaml`). This file includes paths to [validation data](https://www.ultralytics.com/glossary/validation-data), class names, and number of classes.",
                    "Type": "str",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "imgsz",
                    "Default": "640",
                    "Description": "Defines the size of input images. All images are resized to this dimension before processing.",
                    "Type": "int",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "batch",
                    "Default": "16",
                    "Description": "Sets the number of images per batch. Use `-1` for AutoBatch, which automatically adjusts based on GPU memory availability.",
                    "Type": "int",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "save_json",
                    "Default": "False",
                    "Description": "If `True`, saves the results to a JSON file for further analysis or integration with other tools.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "save_hybrid",
                    "Default": "False",
                    "Description": "If `True`, saves a hybrid version of labels that combines original annotations with additional model predictions.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "conf",
                    "Default": "0.001",
                    "Description": "Sets the minimum confidence threshold for detections. Detections with confidence below this threshold are discarded.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "iou",
                    "Default": "0.6",
                    "Description": "Sets the [Intersection Over Union](https://www.ultralytics.com/glossary/intersection-over-union-iou) (IoU) threshold for Non-Maximum Suppression (NMS). Helps in reducing duplicate detections.",
                    "Type": "float",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "max_det",
                    "Default": "300",
                    "Description": "Limits the maximum number of detections per image. Useful in dense scenes to prevent excessive detections.",
                    "Type": "int",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "half",
                    "Default": "True",
                    "Description": "Enables half-[precision](https://www.ultralytics.com/glossary/precision) (FP16) computation, reducing memory usage and potentially increasing speed with minimal impact on [accuracy](https://www.ultralytics.com/glossary/accuracy).",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "device",
                    "Default": "None",
                    "Description": "Specifies the device for validation (`cpu`, `cuda:0`, etc.). Allows flexibility in utilizing CPU or GPU resources.",
                    "Type": "str",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "dnn",
                    "Default": "False",
                    "Description": "If `True`, uses the [OpenCV](https://www.ultralytics.com/glossary/opencv) DNN module for ONNX model inference, offering an alternative to [PyTorch](https://www.ultralytics.com/glossary/pytorch) inference methods.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "plots",
                    "Default": "False",
                    "Description": "When set to `True`, generates and saves plots of predictions versus ground truth for visual evaluation of the model's performance.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "rect",
                    "Default": "True",
                    "Description": "If `True`, uses rectangular inference for batching, reducing padding and potentially increasing speed and efficiency.",
                    "Type": "bool",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "split",
                    "Default": "val",
                    "Description": "Determines the dataset split to use for validation (`val`, `test`, or `train`). Allows flexibility in choosing the data segment for performance evaluation.",
                    "Type": "str",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "project",
                    "Default": "None",
                    "Description": "Name of the project directory where validation outputs are saved.",
                    "Type": "str",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                },
                {
                    "Argument": "name",
                    "Default": "None",
                    "Description": "Name of the validation run. Used for creating a subdirectory within the project folder, where validation logs and outputs are stored.",
                    "Type": "str",
                    "Range": "",
                    "Min": "NaN",
                    "Max": "NaN"
                }
            ]
        }
    ]
}